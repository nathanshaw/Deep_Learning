{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression (AKA Multinomial Logistic Regression)\n",
    "\n",
    "Softmax is a generalization of logistic regression that is used for multi-class classification problems. In multi-class classification, the goal is to predict one of multiple possible classes for a given input. Softmax Regression extends binary logistic regression to handle multiple classes by using a softmax function, which normalizes the output probabilities, ensuring they sum up to 1 across all the classes.\n",
    "\n",
    "In Softmax Regression, the model computes a score for each class, usually using a linear function of input features. These scores are then passed through the softmax function to produce probabilities for each class. The softmax function takes the exponent of each score, and then normalizes the result so that the sum of probabilities for all classes equals 1. Mathematically, the softmax function is defined as:\n",
    "\n",
    "softmax(z)_i = exp(z_i) / Σ(exp(z_j))\n",
    "\n",
    "where z is a vector of scores for each class, and i and j are the indices for the classes.\n",
    "\n",
    "The class with the highest probability is then chosen as the prediction for the input data. During training, the model learns the optimal weights and biases for the linear functions by minimizing a loss function, typically the cross-entropy loss, which measures the discrepancy between the predicted probabilities and the true class labels.\n",
    "\n",
    "Softmax Regression is widely used in various applications, such as image classification, natural language processing, and recommender systems, where the goal is to classify an input into one of multiple possible classes.\n",
    "\n",
    "### Implementing Softmax\n",
    "- C = number of classes you are attempting to identify\n",
    "- If you were classifying cats, dogs, and chicks C would be equal to 4 (as you are also interested in classifying \"other\" or things which are not cats, dogs, and chicks)\n",
    "- You would then build your network so it has four output nodes (instead of one if you were only interested in cat or no cat)\n",
    "- Under this circumstance your shape of Yhat would be (4,1)\n",
    "- To determine what class the sample is a part of, you would simply look at the values of Yhat for that example and select the value which is highest and then use the label associated with that output node.\n",
    "- **IMPORTANT** the summed value of the Yhat vector should be equal to 1.0, so the network is effectively distributing a probability that the image belongs to each of the classes\n",
    "- In order to implement this, you will build what is called a Softmax layer\n",
    "\n",
    "### Building a Softmax Layer\n",
    "- The softmax layer is defined by the use of a specific activation function\n",
    "- t = e^(Z[l])\n",
    "- t will be a (4,1) vector just like Z[l]\n",
    "- a[l] = e^Z[l] / np.sum(t)\n",
    "- a[l] is also a (4,1) vector where a[i] = t[i] / np.sum(t)\n",
    "- **IMPORTANT** what is unusual about this activation function is the fact that it outputs a vector instead of a single real number like the other activation functions we have discussed so far.\n",
    "\n",
    "### Training a Network that Uses a Softmax Layer\n",
    "The loss function commonly used for softmax regression (also known as multiclass logistic regression) is the cross-entropy loss (also called the negative log-likelihood). Given the true probability distribution y and the predicted probability distribution from the softmax function y_hat, the cross-entropy loss is calculated as follows:\n",
    "\n",
    "L(y, y_hat) = - ∑(y_i * log(y_hat_i))\n",
    "\n",
    "Here, the sum runs over all classes i. In the context of classification problems, y is usually a one-hot encoded vector representing the true class label, and y_hat is the predicted probability distribution over the classes obtained by applying the softmax function on the output of the last layer of the neural network.\n",
    "\n",
    "For a single data point, the loss can be calculated as:\n",
    "\n",
    "L = -log(y_hat_c)\n",
    "\n",
    "where y_hat_c is the predicted probability of the true class c.\n",
    "\n",
    "When calculating the loss for a dataset, you compute the average loss across all data points in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
